# -*- coding=utf8 -*-
# Aug 13, 2022
# For testing codes
# Created by Wei Yin

import torchtext.datasets as datasets
import spacy
import io
import os
from real_example import load_tokenizers, tokenize, yield_tokens, getData, build_vocabulary, load_vocab
from torchtext.vocab import build_vocab_from_iterator
import torch
from torch.nn.functional import log_softmax, pad
import torch.nn as nn
from real_example import create_dataloaders

spacy_de, spacy_en = load_tokenizers()
vocab_src, vocab_tgt = load_vocab(spacy_de, spacy_en)
train_dataloader, valid_dataloader = create_dataloaders(
        torch.device("cpu"),
        vocab_src,
        vocab_tgt,
        spacy_de,
        spacy_en,
        batch_size=12000,
        max_padding=128,
        is_distributed=False,
    )

for b in train_dataloader:
    print(b[0].shape)


